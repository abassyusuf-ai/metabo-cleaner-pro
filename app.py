import streamlit as st
import pandas as pd
import numpy as np
import re
from sklearn.decomposition import PCA
from sklearn.cross_decomposition import PLSRegression
from sklearn.ensemble import RandomForestClassifier
import plotly.express as px
from scipy.stats import ttest_ind
from fpdf import FPDF
from pyteomics import mzml
import base64
import gc

# --- 1. PRO CONFIGURATION ---
st.set_page_config(page_title="Metabo-Cleaner Pro | Enterprise", layout="wide", page_icon="ðŸ’Ž")

# --- 2. BUSINESS SIDEBAR (Lead Generation) ---
st.sidebar.title("ðŸ’Ž Metabo-Cleaner Pro")
st.sidebar.info("High-Performance Bioinformatics for Industry & Academia.")

st.sidebar.subheader("ðŸ”¬ Private Consulting")
st.sidebar.write("Need custom pipelines or deeper biological interpretation?")
st.sidebar.markdown("[Contact Abass Yusuf](mailto:abass.bioinformatics@gmail.com?subject=Consulting%20Inquiry)")

st.sidebar.subheader("â˜• Support the Project")
st.sidebar.markdown("[Buy me a coffee](https://www.buymeacoffee.com/abassyusuf)")

st.sidebar.markdown("---")
st.sidebar.caption("Â© 2026 Yusuf Bioinformatics | v2.0 Enterprise")

# --- 3. HELPER: PDF GENERATOR (The Value Add) ---
def create_pdf_report(g1, g2, feat_count, accuracy):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", "B", 16)
    pdf.cell(0, 10, "Metabolomics Discovery Report", ln=True, align="C")
    pdf.set_font("Arial", "", 10)
    pdf.cell(0, 10, "Generated by Metabo-Cleaner Pro Enterprise", ln=True, align="C")
    pdf.ln(10)
    
    pdf.set_font("Arial", "B", 12)
    pdf.cell(0, 10, "1. Executive Summary", ln=True)
    pdf.set_font("Arial", "", 11)
    text = (f"The analysis successfully identified metabolic differences between {g1} and {g2}. "
            f"Using the 80% rule and Pareto scaling, {feat_count} high-quality features were analyzed. "
            f"Machine Learning validation (Random Forest) achieved a cross-validated accuracy of {accuracy:.1%}, "
            "indicating a robust biological signature.")
    pdf.multi_cell(0, 10, text)
    return pdf.output()

# --- 4. MAIN INTERFACE ---
st.title("ðŸ§ª Metabo-Cleaner Pro: Enterprise Discovery Suite")

mode = st.radio("Select Professional Module:", 
                ("Raw mzML Batch Processor (Premium)", "Statistical Discovery (Professional)"))

# ============================================
# MODULE 1: RAW mzML BATCH PROCESSOR
# ============================================
if mode == "Raw mzML Batch Processor (Premium)":
    st.subheader("ðŸš€ High-Throughput Feature Extraction")
    uploaded_mzmls = st.file_uploader("Upload .mzML batch (Unlimited)", type=["mzml"], accept_multiple_files=True)
    
    if uploaded_mzmls and st.button("ðŸš€ Start Enterprise Extraction"):
        all_features = []
        progress = st.progress(0)
        for i, file in enumerate(uploaded_mzmls):
            with open("temp.mzml", "wb") as f: f.write(file.getbuffer())
            rows = []
            with mzml.read("temp.mzml") as reader:
                for spec in reader:
                    if spec['ms level'] == 1 and len(spec['intensity array']) > 0:
                        idx = np.argmax(spec['intensity array'])
                        rows.append([float(spec['m/z array'][idx]), float(spec['scanList']['scan'][0]['scan start time'])/60, float(spec['intensity array'][idx])])
            df_s = pd.DataFrame(rows, columns=["m/z", "RT_min", "Intensity"])
            df_s["Sample"] = file.name.replace(".mzML", "")
            all_features.append(df_s)
            gc.collect()
            progress.progress((i + 1) / len(uploaded_mzmls))
        
        full_df = pd.concat(all_features, ignore_index=True)
        st.success("Extraction Complete.")
        st.download_button("ðŸ“¥ Download Combined Table", full_df.to_csv(index=False).encode('utf-8'), "enterprise_peaks.csv")

# ============================================
# MODULE 2: STATISTICAL DISCOVERY
# ============================================
else:
    uploaded_file = st.file_uploader("Upload your Quantification Table (.csv)", type=["csv"])

    if uploaded_file:
        df = pd.read_csv(uploaded_file)
        with st.expander("âš™ï¸ Advanced Discovery Configuration"):
            c1, c2, c3, c4 = st.columns(4)
            mz_col = c1.selectbox("m/z Column", df.columns, index=0)
            rt_col = c2.selectbox("RT Column", df.columns, index=1 if "RT_min" not in df.columns else df.columns.get_loc("RT_min"))
            sm_col = c3.selectbox("Sample ID", df.columns, index=df.columns.get_loc("Sample") if "Sample" in df.columns else 0)
            in_col = c4.selectbox("Intensity", df.columns, index=df.columns.get_loc("Intensity") if "Intensity" in df.columns else 2)
            
            f1, f2, f3, f4 = st.columns(4)
            mz_bin = f1.slider("m/z Alignment", 1, 5, 3)
            min_pres = f2.slider("Min Presence (%)", 0, 100, 80)
            p_thresh = f3.number_input("P-value Significance", 0.05)
            scaling = f4.selectbox("Scaling", ["Pareto Scaling", "Auto-Scaling", "None"])

        if st.button("ðŸš€ Run Professional Discovery Pipeline"):
            try:
                # --- ENGINE ---
                df['ID'] = df[mz_col].round(mz_bin).astype(str) + "_" + df[rt_col].round(2).astype(str)
                pivot = df.pivot_table(index='ID', columns=sm_col, values=in_col, aggfunc='mean').fillna(0)
                cleaned = pivot[(pivot != 0).sum(axis=1) >= (min_pres/100)*len(pivot.columns)]
                
                # Imputation & TIC
                min_v = cleaned[cleaned > 0].min().min()
                data_ready = cleaned.replace(0, min_v / 2)
                tic_norm = data_ready.div(data_ready.sum(axis=0), axis=1) * 1000000 
                tic_norm = tic_norm[tic_norm.std(axis=1) > 0]

                # --- MATH ---
                groups = [str(s).split('_')[0] for s in tic_norm.columns]
                unique_g = sorted(list(set(groups)))
                X = tic_norm.T
                if scaling == "Pareto Scaling": X_s = (X - X.mean()) / np.sqrt(X.std().replace(0, np.nan))
                else: X_s = (X - X.mean()) / X.std()
                
                pca_res = PCA(n_components=2).fit_transform(X_s)
                pca_var = PCA(n_components=2).fit(X_s).explained_variance_ratio_ * 100

                # --- TABS ---
                t1, t2, t3, t4, t5 = st.tabs(["ðŸ“Š Table", "ðŸ”µ Multivariate", "ðŸŒ‹ Discovery", "ðŸ’Ž Biomarkers", "ðŸ† ML Validation"])
                
                with t1:
                    st.dataframe(tic_norm.head(10))
                    st.download_button("ðŸ“¥ Download Pro Table", tic_norm.to_csv().encode('utf-8'), "pro_cleaned.csv")
                
                with t2:
                    st.plotly_chart(px.scatter(x=pca_res[:,0], y=pca_res[:,1], color=groups, title="Unsupervised PCA"), use_container_width=True)
                
                with t3:
                    if len(unique_g) >= 2:
                        g1_c, g2_c = [c for c in tic_norm.columns if c.startswith(unique_g[0])], [c for c in tic_norm.columns if c.startswith(unique_g[1])]
                        _, pvals = ttest_ind(tic_norm[g1_c], tic_norm[g2_c], axis=1)
                        vol_df = pd.DataFrame({'ID': tic_norm.index, 'p': pvals, 'log10p': -np.log10(pvals)})
                        vol_df['Sig'] = vol_df['p'] < p_thresh
                        st.plotly_chart(px.scatter(vol_df, x='ID', y='log10p', color='Sig', title="Volcano Discovery Map"), use_container_width=True)

                with t4:
                    st.subheader("Top Predictive Biomarkers")
                    significant_hits = vol_df[vol_df['Sig']].sort_values('p')
                    st.dataframe(significant_hits)
                    
                    # THE MONEY BUTTON
                    if st.button("ðŸ’Ž Generate Professional PDF Report"):
                        y_ml = [1 if g == unique_g[-1] else 0 for g in groups]
                        acc = cross_val_score(RandomForestClassifier(), X_s, y_ml, cv=3).mean()
                        report_pdf = create_pdf_report(unique_g[0], unique_g[1], len(significant_hits), acc)
                        st.download_button("ðŸ“¥ Download Final Report (PDF)", data=report_pdf, file_name="Metabo_Discovery_Report.pdf")

                with t5:
                    y_ml = [1 if g == unique_g[-1] else 0 for g in groups]
                    acc = cross_val_score(RandomForestClassifier(), X_s, y_ml, cv=3).mean()
                    st.metric("Random Forest Predictive Accuracy", f"{acc:.1%}")
                    st.info("Industry standard: Accuracy > 85% is required for diagnostic applications.")

                st.balloons()
            except Exception as e:
                st.error(f"Error: {e}")

st.markdown("---")
st.caption("ðŸ”’ Privacy Shield: Data processed in-memory only. No storage on server.")
